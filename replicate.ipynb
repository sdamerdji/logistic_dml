{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dc120a1-b7a5-44ab-b759-257147bc9354",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed42050-d045-4609-ba1a-27e42bf69f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8016f267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from logistic_dml import DML\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier,RandomForestClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.svm import SVR,SVC\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold, f_regression\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, QuantileTransformer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import PolynomialFeatures, SplineTransformer, PowerTransformer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow import keras \n",
    "from scipy import stats\n",
    "from sklearn.linear_model import SGDClassifier, SGDRegressor\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bab2e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv( '../../Dataset2_BirthAge20-34_subset10000.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47f9967c-ed59-4ac1-9c98-9a7195ca0d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5947, 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.birth==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b8e49f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train =df.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a692e1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train['birth']\n",
    "A = train['pill']\n",
    "X = train.drop(['pill','birth'], axis=1)\n",
    "K=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60493e2d-c79d-49f6-af1e-444e9a1d44f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebabfda4-2020-447d-9555-abc2a1684f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions for fold k = 1\n",
      "Predicting M_hat\n",
      "Getting predictions for subfold j = 1\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 2\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 3\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 4\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 5\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Predicting t_hat\n",
      "Getting predictions for fold k = 2\n",
      "Predicting M_hat\n",
      "Getting predictions for subfold j = 1\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 2\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 3\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 4\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 5\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Predicting t_hat\n",
      "Getting predictions for fold k = 3\n",
      "Predicting M_hat\n",
      "Getting predictions for subfold j = 1\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 2\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 3\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 4\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 5\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Predicting t_hat\n",
      "Getting predictions for fold k = 4\n",
      "Predicting M_hat\n",
      "Getting predictions for subfold j = 1\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 2\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 3\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 4\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 5\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Predicting t_hat\n",
      "Getting predictions for fold k = 5\n",
      "Predicting M_hat\n",
      "Getting predictions for subfold j = 1\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 2\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 3\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 4\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 5\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Predicting t_hat\n",
      "Root finding using root_scalar failed: f(a) and f(b) must have different signs\n",
      "Root finding using root_scalar failed: f(a) and f(b) must have different signs\n",
      "Root finding using root_scalar failed: f(a) and f(b) must have different signs\n",
      "Root finding using root_scalar failed: f(a) and f(b) must have different signs\n",
      "[ 0.07771752  0.69559006 -0.05297876  0.03809705  0.09825369 -0.15287515\n",
      "  0.11094703 -0.02803392  1.99999424 -0.60108051 -0.32640673  0.35232986\n",
      " -0.1527411  -0.14542055 -0.79398888  1.99999424 -0.54332155 -0.05191774\n",
      "  0.14521561  1.29103233 -0.26803571  0.32168716  0.15545785 -0.18950545\n",
      "  0.34564151 -0.13182136 -0.13173552  0.06578334 -0.02111928 -0.5602238\n",
      "  0.28173054 -0.41642392 -0.68953417 -0.43036583 -0.00964287  0.39384599\n",
      " -0.42206561  0.08363464 -0.29114733 -0.07348864 -0.28514892  0.09737208\n",
      " -0.31809157 -0.03126096 -0.00401749  0.13860383  0.47869872 -0.61234413\n",
      " -0.59708156 -0.61296811 -0.49330548 -0.261895    0.48412097 -0.49240096\n",
      " -0.03376831 -0.62473868 -0.16297985  0.48205789  0.11243492 -0.55931323\n",
      "  0.5950891   0.34302315  0.71793391  1.99999424  0.26619421 -1.21626365\n",
      " -0.87159859 -0.71643538  0.05657078  0.76775378 -0.43707753 -0.37776345\n",
      "  0.60079949 -0.28468831 -0.01813723  0.0853132  -0.138748   -0.30947741\n",
      "  0.04677341 -0.27424422 -0.32620028  0.30228828  0.08635144  0.44211987\n",
      " -0.43446027 -0.47816578 -0.20374264  0.83538456 -0.58090148 -0.71415239\n",
      "  0.97661306 -0.81435501 -0.2880076  -0.54778335 -0.0312573   0.2175029\n",
      " -0.07302189  0.14451241  0.28632782  0.11662015 -0.44073143 -0.57196577\n",
      " -0.10900288 -0.23243369 -0.07094666  0.13704546 -0.21680378 -0.42752815\n",
      "  0.52257085 -0.10992113  0.19709447  0.35524737  0.67461022  0.44268709\n",
      " -0.83765604 -0.57167934 -0.23389184 -0.38907123  0.17197277 -0.13038241\n",
      " -0.60841926 -0.28864842 -0.68511157 -0.16667159  0.2393123  -0.55500947\n",
      " -0.31452035 -0.42034004 -0.33235872 -0.60641016  0.05054571  0.63058441\n",
      "  1.53476837 -0.18079023 -0.20035758 -0.4626459  -0.44270291  0.73916179\n",
      "  0.39454282 -0.13512711 -0.37826147  0.21051882 -0.46204954  1.15426806\n",
      " -0.47188753 -0.43756751 -0.68512075  0.64942028 -0.44772913  0.5877452\n",
      " -0.38277706 -0.58188921  1.99999424 -0.2442162  -0.0692726   0.00349559\n",
      "  0.04587162 -0.09783331 -0.08514165  0.32536605 -0.21613804 -0.77364827\n",
      "  1.2819365  -0.6582036  -0.52507233 -0.58610793  0.14232431 -0.08091785\n",
      "  0.15416468  0.48989736  1.00542288 -0.64877379 -0.67607711 -0.02547413\n",
      " -0.57595507  0.05710469 -0.71219586 -0.33013307 -0.70195052 -0.84751967\n",
      "  0.15954915 -0.00988668 -0.44452559 -0.53125982  0.06161096  0.11503704\n",
      " -0.37000742 -0.94888557 -0.02792512 -0.58087908  0.0363659   0.07299645\n",
      " -0.2934037   0.06987565 -0.19439988 -0.36088488 -0.5284478  -0.50056283\n",
      " -0.35515529  0.372895  ]\n",
      "beta hat -0.15433013635298448\n",
      "p value 0.725\n",
      "ci (-0.6677243884584676, 0.3590641157524987)\n",
      "lb -0.15280477787014105\n",
      "ub -0.09180477179846895\n"
     ]
    }
   ],
   "source": [
    "result_gb = DML(\n",
    "        Y=Y,\n",
    "        A=A,\n",
    "        X=X,classifier=GradientBoostingClassifier(), regressor=GradientBoostingRegressor(),random_seed=0, k_folds=K,\n",
    "    # M_hat_classifier=GradientBoostingClassifier(),\n",
    "    #          a_hat_classifier=GradientBoostingClassifier()\n",
    ")      \n",
    "\n",
    "\n",
    "result_gb.train()\n",
    "lb_gb, ub_gb, mean_gb, sd_gb = result_gb.significance_testing()\n",
    "\n",
    "print('beta hat', result_gb.beta_hat)\n",
    "print('p value', result_gb.p_value)\n",
    "print('ci', result_gb.ci)\n",
    "print('lb', lb_gb)\n",
    "print('ub', ub_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c966649-6dbf-42da-8774-d42ddeb1409c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1,\n",
       " 'max_depth': 3,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 10,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4a5cf019-623e-4e98-a810-71fef14da351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 25, 'min_samples_leaf': 0.01}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1615c7e-1906-4224-8fb1-13d1f6ccb302",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_params = {'max_depth': 10,\n",
    " 'max_features': 'log2',\n",
    " 'min_samples_leaf': 4,\n",
    " 'min_samples_split': 10,\n",
    " 'n_estimators': 100}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "041f086e-c56e-41f2-97a5-f510f3aff52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_params ={'max_depth': 10,\n",
    " 'max_features': 'sqrt',\n",
    " 'min_samples_leaf': 4,\n",
    " 'min_samples_split': 10,\n",
    " 'n_estimators': 200}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3526ee8b-facb-494e-95c5-9991b4b39853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions for fold k = 1\n",
      "Predicting M_hat\n",
      "Getting predictions for subfold j = 1\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 2\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 3\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 4\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 5\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Predicting t_hat\n",
      "Getting predictions for fold k = 2\n",
      "Predicting M_hat\n",
      "Getting predictions for subfold j = 1\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 2\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 3\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 4\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 5\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Predicting t_hat\n",
      "Getting predictions for fold k = 3\n",
      "Predicting M_hat\n",
      "Getting predictions for subfold j = 1\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 2\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 3\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 4\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 5\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Predicting t_hat\n",
      "Getting predictions for fold k = 4\n",
      "Predicting M_hat\n",
      "Getting predictions for subfold j = 1\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 2\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 3\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 4\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 5\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Predicting t_hat\n",
      "Getting predictions for fold k = 5\n",
      "Predicting M_hat\n",
      "Getting predictions for subfold j = 1\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 2\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 3\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 4\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 5\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Predicting t_hat\n",
      "[-0.19301303 -0.01383217 -0.03608038 -0.09935215  0.01894779 -0.29362956\n",
      " -0.05685669 -0.06051195 -0.04909893 -0.36273461  0.02232242  0.16571447\n",
      " -0.29813656 -0.03625205 -0.18293425  0.01624133 -0.30687476 -0.2430638\n",
      "  0.05571104 -0.12387037 -0.13448222 -0.16204873  0.06583701 -0.18382913\n",
      " -0.0026389  -0.13343043 -0.10179635 -0.23776374 -0.26124875 -0.28878285\n",
      " -0.09225322 -0.29028875 -0.17601375 -0.43176494 -0.26609308 -0.13743008\n",
      " -0.18871415 -0.22009696 -0.24985333 -0.03588962 -0.12685797 -0.0631088\n",
      " -0.19259441 -0.24511476 -0.06295982 -0.26857727 -0.07725859 -0.11064064\n",
      " -0.05919832 -0.21879374 -0.26306815 -0.1525381   0.01769521 -0.33223071\n",
      " -0.07503783 -0.22046976 -0.17169314 -0.0900028  -0.0144124  -0.19939576\n",
      " -0.04417297 -0.11594763  0.069373    0.07975051 -0.0820491  -0.24855694\n",
      " -0.21612409 -0.15178565 -0.18989488 -0.13715679 -0.16665485 -0.06097136\n",
      "  0.08405947 -0.27066806  0.0062098   0.04471996 -0.2534574  -0.04516831\n",
      " -0.04504496 -0.20897893 -0.06117938 -0.0535978  -0.01547812 -0.05978448\n",
      " -0.10901182 -0.23382828 -0.03132092 -0.14332366 -0.29196505 -0.17926344\n",
      " -0.13771023 -0.3145572  -0.26283278 -0.16845602 -0.08828217 -0.12391874\n",
      " -0.22334608 -0.25982723  0.00350821 -0.22086322 -0.32501893 -0.17841214\n",
      " -0.03611328 -0.3027599  -0.11942635 -0.19957529 -0.2139328  -0.23207123\n",
      " -0.13818944 -0.03853922 -0.23680119 -0.25951966 -0.05916584  0.0124491\n",
      " -0.33133941 -0.20984807  0.00568249 -0.11243535 -0.16564858  0.00594573\n",
      " -0.35644448 -0.21804774 -0.29525502 -0.16598074 -0.18354251 -0.00326243\n",
      " -0.15754532  0.02683466 -0.14708145 -0.29341475 -0.12164858  0.02970419\n",
      "  0.06819155 -0.15875915 -0.27755417 -0.20762393 -0.1457107  -0.03753353\n",
      " -0.24976829 -0.13090707 -0.22900032 -0.03428339 -0.20620961  0.04406805\n",
      " -0.2683317  -0.26801135 -0.23064742 -0.2200749  -0.20997997  0.20442105\n",
      " -0.17766677 -0.14640082 -0.00932686 -0.0644994  -0.05098936 -0.17163966\n",
      " -0.12146081 -0.12226009 -0.1584683  -0.1253812  -0.2976019  -0.29732567\n",
      "  0.12735423 -0.15647282 -0.37811573 -0.26600298 -0.07754918 -0.11202622\n",
      " -0.2550916   0.05139808  0.02292797 -0.40030627 -0.36152601 -0.1308849\n",
      " -0.15741705 -0.16837365 -0.18841718 -0.13103201 -0.17585134 -0.14395606\n",
      " -0.17637218 -0.10855803 -0.23422962 -0.35795124 -0.19634965 -0.17743692\n",
      " -0.25190865 -0.35472768 -0.14548484 -0.38749906 -0.21813096 -0.15155809\n",
      " -0.19664631 -0.14386352 -0.1484103  -0.34086492 -0.17305254 -0.21617098\n",
      " -0.17441454 -0.06858968]\n",
      "beta hat -0.16375755051297375\n",
      "p value 0.165\n",
      "ci (-0.27450796574810277, -0.05300713527784473)\n",
      "lb -0.16580635633849639\n",
      "ub -0.15006288810546348\n"
     ]
    }
   ],
   "source": [
    "result_rf = DML(\n",
    "        Y=Y,\n",
    "        A=A,\n",
    "        X=X,classifier=RandomForestClassifier(**rfc_params), regressor=RandomForestRegressor(**rfr_params),\n",
    "    random_seed=0,\n",
    "    k_folds=K,    \n",
    "\n",
    ")      \n",
    "result_rf.train()\n",
    "\n",
    "lb_rf, ub_rf, mean_rf, sd_rf = result_rf.significance_testing()\n",
    "print('beta hat', result_rf.beta_hat)\n",
    "print('p value', result_rf.p_value)\n",
    "print('ci', result_rf.ci)\n",
    "print('lb', lb_rf)\n",
    "print('ub', ub_rf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b30def3-c7ed-4bf7-a859-00a969d01a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 100}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a06921dc-e8a6-44c2-8526-23c3175b12b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV 1/5] END C=0.01, epsilon=0.1, kernel=linear;, score=-0.486 total time=   1.2s\n",
      "[CV 2/5] END C=0.01, epsilon=0.1, kernel=linear;, score=-0.489 total time=   1.1s\n",
      "[CV 3/5] END C=0.01, epsilon=0.1, kernel=linear;, score=-0.488 total time=   1.2s\n",
      "[CV 4/5] END C=0.01, epsilon=0.1, kernel=linear;, score=-0.497 total time=   1.2s\n",
      "[CV 5/5] END C=0.01, epsilon=0.1, kernel=linear;, score=-0.494 total time=   1.2s\n",
      "[CV 1/5] END C=0.01, epsilon=0.2, kernel=linear;, score=-0.469 total time=   1.1s\n",
      "[CV 2/5] END C=0.01, epsilon=0.2, kernel=linear;, score=-0.476 total time=   1.1s\n",
      "[CV 3/5] END C=0.01, epsilon=0.2, kernel=linear;, score=-0.475 total time=   1.1s\n",
      "[CV 4/5] END C=0.01, epsilon=0.2, kernel=linear;, score=-0.477 total time=   1.1s\n",
      "[CV 5/5] END C=0.01, epsilon=0.2, kernel=linear;, score=-0.475 total time=   1.1s\n",
      "[CV 1/5] END C=0.01, epsilon=0.5, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 2/5] END C=0.01, epsilon=0.5, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 3/5] END C=0.01, epsilon=0.5, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 4/5] END C=0.01, epsilon=0.5, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 5/5] END C=0.01, epsilon=0.5, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 1/5] END .C=0.01, epsilon=1, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 2/5] END .C=0.01, epsilon=1, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 3/5] END .C=0.01, epsilon=1, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 4/5] END .C=0.01, epsilon=1, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 5/5] END .C=0.01, epsilon=1, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, epsilon=0.1, kernel=linear;, score=-0.487 total time=   1.5s\n",
      "[CV 2/5] END C=0.1, epsilon=0.1, kernel=linear;, score=-0.490 total time=   1.5s\n",
      "[CV 3/5] END C=0.1, epsilon=0.1, kernel=linear;, score=-0.490 total time=   1.5s\n",
      "[CV 4/5] END C=0.1, epsilon=0.1, kernel=linear;, score=-0.500 total time=   1.5s\n",
      "[CV 5/5] END C=0.1, epsilon=0.1, kernel=linear;, score=-0.496 total time=   1.6s\n",
      "[CV 1/5] END C=0.1, epsilon=0.2, kernel=linear;, score=-0.469 total time=   1.4s\n",
      "[CV 2/5] END C=0.1, epsilon=0.2, kernel=linear;, score=-0.476 total time=   1.3s\n",
      "[CV 3/5] END C=0.1, epsilon=0.2, kernel=linear;, score=-0.475 total time=   1.4s\n",
      "[CV 4/5] END C=0.1, epsilon=0.2, kernel=linear;, score=-0.477 total time=   1.3s\n",
      "[CV 5/5] END C=0.1, epsilon=0.2, kernel=linear;, score=-0.475 total time=   1.3s\n",
      "[CV 1/5] END C=0.1, epsilon=0.5, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, epsilon=0.5, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, epsilon=0.5, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, epsilon=0.5, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, epsilon=0.5, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.1, epsilon=1, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, epsilon=1, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, epsilon=1, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, epsilon=1, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, epsilon=1, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 1/5] END ..C=1, epsilon=0.1, kernel=linear;, score=-0.487 total time=   3.3s\n",
      "[CV 2/5] END ..C=1, epsilon=0.1, kernel=linear;, score=-0.490 total time=   3.2s\n",
      "[CV 3/5] END ..C=1, epsilon=0.1, kernel=linear;, score=-0.490 total time=   3.3s\n",
      "[CV 4/5] END ..C=1, epsilon=0.1, kernel=linear;, score=-0.500 total time=   3.4s\n",
      "[CV 5/5] END ..C=1, epsilon=0.1, kernel=linear;, score=-0.496 total time=   3.3s\n",
      "[CV 1/5] END ..C=1, epsilon=0.2, kernel=linear;, score=-0.469 total time=   3.1s\n",
      "[CV 2/5] END ..C=1, epsilon=0.2, kernel=linear;, score=-0.476 total time=   2.8s\n",
      "[CV 3/5] END ..C=1, epsilon=0.2, kernel=linear;, score=-0.475 total time=   2.9s\n",
      "[CV 4/5] END ..C=1, epsilon=0.2, kernel=linear;, score=-0.477 total time=   3.0s\n",
      "[CV 5/5] END ..C=1, epsilon=0.2, kernel=linear;, score=-0.475 total time=   3.0s\n",
      "[CV 1/5] END ..C=1, epsilon=0.5, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 2/5] END ..C=1, epsilon=0.5, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 3/5] END ..C=1, epsilon=0.5, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 4/5] END ..C=1, epsilon=0.5, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 5/5] END ..C=1, epsilon=0.5, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 1/5] END ....C=1, epsilon=1, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 2/5] END ....C=1, epsilon=1, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 3/5] END ....C=1, epsilon=1, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 4/5] END ....C=1, epsilon=1, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 5/5] END ....C=1, epsilon=1, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 1/5] END .C=10, epsilon=0.1, kernel=linear;, score=-0.487 total time=  15.8s\n",
      "[CV 2/5] END .C=10, epsilon=0.1, kernel=linear;, score=-0.490 total time=  15.8s\n",
      "[CV 3/5] END .C=10, epsilon=0.1, kernel=linear;, score=-0.490 total time=  16.3s\n",
      "[CV 4/5] END .C=10, epsilon=0.1, kernel=linear;, score=-0.500 total time=  16.9s\n",
      "[CV 5/5] END .C=10, epsilon=0.1, kernel=linear;, score=-0.496 total time=  17.8s\n",
      "[CV 1/5] END .C=10, epsilon=0.2, kernel=linear;, score=-0.469 total time=  14.8s\n",
      "[CV 2/5] END .C=10, epsilon=0.2, kernel=linear;, score=-0.476 total time=  14.0s\n",
      "[CV 3/5] END .C=10, epsilon=0.2, kernel=linear;, score=-0.475 total time=  15.0s\n",
      "[CV 4/5] END .C=10, epsilon=0.2, kernel=linear;, score=-0.478 total time=  15.2s\n",
      "[CV 5/5] END .C=10, epsilon=0.2, kernel=linear;, score=-0.475 total time=  15.5s\n",
      "[CV 1/5] END .C=10, epsilon=0.5, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 2/5] END .C=10, epsilon=0.5, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 3/5] END .C=10, epsilon=0.5, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 4/5] END .C=10, epsilon=0.5, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 5/5] END .C=10, epsilon=0.5, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 1/5] END ...C=10, epsilon=1, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 2/5] END ...C=10, epsilon=1, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 3/5] END ...C=10, epsilon=1, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 4/5] END ...C=10, epsilon=1, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "[CV 5/5] END ...C=10, epsilon=1, kernel=linear;, score=-0.500 total time=   0.0s\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "[CV 1/5] END ............C=0.01, kernel=linear;, score=-0.587 total time=   1.0s\n",
      "[CV 2/5] END ............C=0.01, kernel=linear;, score=-0.581 total time=   1.0s\n",
      "[CV 3/5] END ............C=0.01, kernel=linear;, score=-0.593 total time=   1.0s\n",
      "[CV 4/5] END ............C=0.01, kernel=linear;, score=-0.597 total time=   1.0s\n",
      "[CV 5/5] END ............C=0.01, kernel=linear;, score=-0.585 total time=   1.1s\n",
      "[CV 1/5] END .............C=0.1, kernel=linear;, score=-0.588 total time=   1.4s\n",
      "[CV 2/5] END .............C=0.1, kernel=linear;, score=-0.583 total time=   1.5s\n",
      "[CV 3/5] END .............C=0.1, kernel=linear;, score=-0.595 total time=   1.2s\n",
      "[CV 4/5] END .............C=0.1, kernel=linear;, score=-0.596 total time=   1.2s\n",
      "[CV 5/5] END .............C=0.1, kernel=linear;, score=-0.586 total time=   1.1s\n",
      "[CV 1/5] END ...............C=1, kernel=linear;, score=-0.587 total time=   1.6s\n",
      "[CV 2/5] END ...............C=1, kernel=linear;, score=-0.583 total time=   1.7s\n",
      "[CV 3/5] END ...............C=1, kernel=linear;, score=-0.594 total time=   1.6s\n",
      "[CV 4/5] END ...............C=1, kernel=linear;, score=-0.596 total time=   1.7s\n",
      "[CV 5/5] END ...............C=1, kernel=linear;, score=-0.587 total time=   1.7s\n",
      "[CV 1/5] END ..............C=10, kernel=linear;, score=-0.587 total time=   4.3s\n",
      "[CV 2/5] END ..............C=10, kernel=linear;, score=-0.583 total time=   4.2s\n",
      "[CV 3/5] END ..............C=10, kernel=linear;, score=-0.594 total time=   4.6s\n",
      "[CV 4/5] END ..............C=10, kernel=linear;, score=-0.597 total time=   4.3s\n",
      "[CV 5/5] END ..............C=10, kernel=linear;, score=-0.587 total time=   4.3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10], &#x27;kernel&#x27;: [&#x27;linear&#x27;]},\n",
       "             scoring=&#x27;neg_root_mean_squared_error&#x27;, verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10], &#x27;kernel&#x27;: [&#x27;linear&#x27;]},\n",
       "             scoring=&#x27;neg_root_mean_squared_error&#x27;, verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10], 'kernel': ['linear']},\n",
       "             scoring='neg_root_mean_squared_error', verbose=3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_reg = {\n",
    "    'C': [0.01,0.1, 1, 10],\n",
    "    'kernel': ['linear'],\n",
    "    'epsilon': [0.1, 0.2, 0.5, 1]\n",
    "}\n",
    "param_grid_cl = {\n",
    "    'C': [0.01,0.1, 1, 10],\n",
    "    'kernel': ['linear'],\n",
    "\n",
    "}\n",
    "# Initialize the SVR model\n",
    "svr = SVR()\n",
    "svc = SVC()\n",
    "\n",
    "# Perform Grid Search with neg_mean_squared_error as the scoring metric\n",
    "grid_search_reg = GridSearchCV(estimator=svr, param_grid=param_grid_reg, cv=5,  verbose=3, scoring='neg_root_mean_squared_error')\n",
    "grid_search_reg.fit(X, Y)\n",
    "grid_search_cl = GridSearchCV(estimator=svc, param_grid=param_grid_cl, cv=5, verbose=3, scoring='neg_root_mean_squared_error')\n",
    "grid_search_cl.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "555daef0-4f3f-46e5-8beb-013e3b3d2323",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=grid_search_cl.best_params_\n",
    "a['probability']=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24c17a74-afde-43fd-b9ea-49038d3f10a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting predictions for fold k = 1\n",
      "Predicting M_hat\n",
      "Getting predictions for subfold j = 1\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 2\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 3\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 4\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 5\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Predicting t_hat\n",
      "Getting predictions for fold k = 2\n",
      "Predicting M_hat\n",
      "Getting predictions for subfold j = 1\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 2\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 3\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 4\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 5\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Predicting t_hat\n",
      "Getting predictions for fold k = 3\n",
      "Predicting M_hat\n",
      "Getting predictions for subfold j = 1\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 2\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 3\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 4\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 5\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Predicting t_hat\n",
      "Getting predictions for fold k = 4\n",
      "Predicting M_hat\n",
      "Getting predictions for subfold j = 1\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 2\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 3\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 4\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 5\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Predicting t_hat\n",
      "Getting predictions for fold k = 5\n",
      "Predicting M_hat\n",
      "Getting predictions for subfold j = 1\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 2\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 3\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 4\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Getting predictions for subfold j = 5\n",
      "Predicting M_hat\n",
      "Predicting a_hat\n",
      "Predicting t_hat\n",
      "[-0.17427783  0.03250128  0.16122039  0.03679031  0.10911147 -0.16454245\n",
      " -0.1073805  -0.04539618 -0.05314252 -0.31675523  0.01699265  0.37626375\n",
      " -0.29613912 -0.1237552  -0.34754569  0.3358419  -0.27858397 -0.28799899\n",
      "  0.16737053  0.02476109 -0.13664964 -0.13201359  0.0726554  -0.13175932\n",
      "  0.03892931 -0.04729902 -0.07677456 -0.26314914 -0.16469091 -0.29797381\n",
      " -0.06277798 -0.26950165 -0.04899419 -0.64458597 -0.12597073 -0.00281619\n",
      " -0.12983709 -0.14404204 -0.42009993 -0.07143101 -0.03951397  0.21994833\n",
      " -0.08898689 -0.26875517  0.07976882 -0.37111367 -0.10144957 -0.0713894\n",
      "  0.02480383 -0.23763587 -0.15644359 -0.34358537  0.10744389 -0.42370191\n",
      "  0.05855505 -0.17881631 -0.3270827   0.01176601 -0.04267656 -0.16954126\n",
      " -0.05430598  0.00610275  0.04230362  0.18559028 -0.21772106 -0.25082141\n",
      " -0.09170886 -0.27045935 -0.23703411 -0.1143473  -0.02817457 -0.16247323\n",
      "  0.27867025 -0.21503926  0.16035051  0.10326425 -0.13791874  0.10386796\n",
      " -0.11694314 -0.18395352  0.0566299  -0.20854167  0.00381823 -0.00454748\n",
      " -0.28785703 -0.25205025 -0.11189165 -0.23105038 -0.13452249 -0.38871162\n",
      " -0.11926403 -0.36601531 -0.27577856 -0.1768889  -0.08498566 -0.20225068\n",
      " -0.36356443 -0.17407719  0.09197998 -0.16479985 -0.49139676 -0.2617911\n",
      " -0.18997058 -0.48907968 -0.05678819 -0.34725522 -0.34820393 -0.2495789\n",
      " -0.1264666   0.05667875 -0.15202989 -0.14799499 -0.08746473  0.13068189\n",
      " -0.31678055 -0.21292212  0.01554228 -0.16324281  0.01225838  0.16114863\n",
      " -0.62041339 -0.1725223  -0.41945449 -0.34396912 -0.15200376  0.06371281\n",
      " -0.22670287  0.08028577 -0.10148746 -0.34516597 -0.17630013  0.10266312\n",
      " -0.15004222 -0.09225497 -0.33333201 -0.2783732  -0.23683839 -0.0842121\n",
      " -0.34190399 -0.22436899 -0.29096195 -0.13902385 -0.09661837  0.0839095\n",
      " -0.15927368 -0.33841195 -0.3984955  -0.38669274 -0.31755921  0.36404397\n",
      " -0.1815945  -0.23228194 -0.1333974  -0.08401755 -0.1031994  -0.17867892\n",
      " -0.10081154 -0.20240359 -0.26234709 -0.21936587 -0.40997011 -0.24422549\n",
      "  0.22856769 -0.14311879 -0.44028861 -0.26795712 -0.00873105 -0.17016907\n",
      " -0.1150852   0.0766434  -0.05561693 -0.56923543 -0.58353284 -0.13216971\n",
      " -0.29739152 -0.10842979 -0.09545726 -0.09765365 -0.1839509  -0.28893201\n",
      " -0.25446012 -0.17601543 -0.23171889 -0.29091225 -0.19249217 -0.12344103\n",
      " -0.33428896 -0.46665727 -0.25038178 -0.47991231 -0.26189925 -0.30355194\n",
      " -0.14369617 -0.10096253 -0.21290744 -0.55099976 -0.25556537 -0.16487727\n",
      " -0.28919467  0.20512813]\n",
      "beta hat -0.1727575035984677\n",
      "p value 0.325\n",
      "ci (-0.3442800396767627, -0.0012349675201726862)\n",
      "lb -0.16474266078355132\n",
      "ub -0.14611733542447974\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "result_sv = DML(\n",
    "        Y=Y,\n",
    "        A=A,\n",
    "        X=X,classifier=SVC(**a), regressor=SVR(**grid_search_reg.best_params_),random_seed=0, k_folds=K,\n",
    "        # M_hat_classifier=SVC(probability=True,kernel='linear'),\n",
    "        # a_hat_classifier=SVC(probability=True,kernel='linear'),)      \n",
    ")\n",
    "\n",
    "result_sv.train()\n",
    "\n",
    "lb_sv, ub_sv, mean_sv, sd_sv = result_sv.significance_testing()\n",
    "print('beta hat', result_sv.beta_hat)\n",
    "print('p value', result_sv.p_value)\n",
    "print('ci', result_sv.ci)\n",
    "print('lb', lb_sv)\n",
    "print('ub', ub_sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b580ad7-0069-4d25-98e2-1f9caf1d7ffa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_nnr \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241m.\u001b[39mSequential([ \n\u001b[1;32m      2\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m5\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(X_rs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],), \n\u001b[1;32m      3\u001b[0m                        activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m),keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m5\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m)]) \n\u001b[1;32m      4\u001b[0m model_nnr\u001b[38;5;241m.\u001b[39mcompile( \n\u001b[1;32m      5\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      6\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      7\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]) \n\u001b[1;32m      8\u001b[0m model_nnc \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mSequential([ \n\u001b[1;32m      9\u001b[0m     keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m5\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(X_rs\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],), \n\u001b[1;32m     10\u001b[0m                        activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m5\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m),keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msigmoid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m ]) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_nnr = keras.Sequential([ \n",
    "    keras.layers.Dense(5, input_shape=(X_rs.shape[1],), \n",
    "                       activation='sigmoid'),keras.layers.Dense(5, activation='relu'),keras.layers.Dense(1)]) \n",
    "model_nnr.compile( \n",
    "    optimizer='adam', \n",
    "    loss='mean_squared_error', \n",
    "    metrics=['accuracy']) \n",
    "model_nnc = keras.Sequential([ \n",
    "    keras.layers.Dense(5, input_shape=(X_rs.shape[1],), \n",
    "                       activation='relu'),keras.layers.Dense(5, activation='relu'),keras.layers.Dense(units=1, activation='sigmoid')\n",
    "]) \n",
    "model_nnc.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "result_nn = DML(\n",
    "        Y=y_rs,\n",
    "        A=A_rs,\n",
    "        X=X_rs,classifier=model_nnc , regressor=model_nnr,random_seed=0, k_folds=K)      \n",
    "\n",
    "\n",
    "result_nn.train()\n",
    "\n",
    "lb_nn, ub_nn, mean_nn, sd_nn = result_sv.significance_testing()\n",
    "print('beta hat', result_nn.beta_hat)\n",
    "print('p value', result_nn.p_value)\n",
    "print('ci', result_nn.ci)\n",
    "print('lb', lb_nn)\n",
    "print('ub', ub_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11642866-14c6-4fca-b58a-8aa3385b72b7",
   "metadata": {},
   "source": [
    "for tensorflow<=2.5, predict_proba is  deprectaed and no longer in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34001482-ad81-4aee-a54e-ac46331a9e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'ML':['GB','RF','SVM'],'Beta':[result_gb.beta_hat,result_rf.beta_hat,result_sv.beta_hat],\n",
    "       'CI_LB':[result_gb.ci[0],result_rf.ci[0],result_sv.ci[0]], \n",
    "        \"CI_UB\":[result_gb.ci[1],result_rf.ci[1],result_sv.ci[1]],\n",
    "        \"p_val\":[result_gb.p_value,result_rf.p_value,result_sv.p_value]}\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d5d4d22-2c62-4f3b-a897-ba1cfc89a9aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML</th>\n",
       "      <th>Beta</th>\n",
       "      <th>CI_LB</th>\n",
       "      <th>CI_UB</th>\n",
       "      <th>p_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GB</td>\n",
       "      <td>-0.154330</td>\n",
       "      <td>-0.667724</td>\n",
       "      <td>0.359064</td>\n",
       "      <td>0.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>-0.163758</td>\n",
       "      <td>-0.274508</td>\n",
       "      <td>-0.053007</td>\n",
       "      <td>0.165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM</td>\n",
       "      <td>-0.172758</td>\n",
       "      <td>-0.344280</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>0.325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ML      Beta     CI_LB     CI_UB  p_val\n",
       "0   GB -0.154330 -0.667724  0.359064  0.725\n",
       "1   RF -0.163758 -0.274508 -0.053007  0.165\n",
       "2  SVM -0.172758 -0.344280 -0.001235  0.325"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc3dd19-97e8-4fe4-bea8-cea62a61c493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df37f5d-e711-4398-839e-90508e68b791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
